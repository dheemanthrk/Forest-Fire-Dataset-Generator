Here's the README file in proper Markdown format. You can copy and paste it directly into your repository as `README.md`.

---

# ğŸ”¥ Forest Fire Data Processing Tool ğŸŒ

A comprehensive tool for processing **climate**, **NDVI**, **fire history**, and **topographical** data for machine learning-based forest fire prediction.

---

## ğŸ“‚ Project Structure

```
â”œâ”€â”€ ğŸ“ Data
â”‚   â”œâ”€â”€ ğŸ“ Grid                  # Shapefiles for each province
â”‚   â”œâ”€â”€ ğŸ“ FireHistory           # Fire history dataset
â”‚   â”œâ”€â”€ ğŸ“ credentials           # API credentials (ğŸš¨ Not included in the repository)
â”‚
â”œâ”€â”€ ğŸ“ Output
â”‚   â”œâ”€â”€ ğŸ“ Requests              # Stores all processed data per request
â”‚       â”œâ”€â”€ ğŸ“ Request_YYYYMMDD_HHMM
â”‚           â”œâ”€â”€ ğŸ“ Climate       # Processed climate data
â”‚           â”œâ”€â”€ ğŸ“ FireHistory   # Processed fire history data
â”‚           â”œâ”€â”€ ğŸ“ NDVI          # NDVI data (raw + interpolated)
â”‚           â”œâ”€â”€ ğŸ“ Topography    # DEM, slope, and aspect data
â”‚           â”œâ”€â”€ ğŸ—‚ merged_data.csv  # Final merged dataset
â”‚
â”œâ”€â”€ ğŸ“œ process_climate.py        # Fetches & processes climate data
â”œâ”€â”€ ğŸ“œ process_ndvi.py           # Fetches & processes NDVI data
â”œâ”€â”€ ğŸ“œ process_fire_history.py   # Processes fire history data
â”œâ”€â”€ ğŸ“œ process_topo.py           # Fetches & processes topographical data
â”œâ”€â”€ ğŸ“œ merge_data.py             # Merges all processed data
â”œâ”€â”€ ğŸ“œ main.py                   # Main script for execution
â”œâ”€â”€ ğŸ“œ README.md                 # You're reading it! ğŸ“–
```

## ğŸ”‘ Setting Up CDS API Credentials

The **CDS API** (Copernicus Data Service) is required to fetch climate and topographical data. Follow these steps to set up your credentials:

### 1ï¸âƒ£ **Create a CDS Account**
1. Go to the **Copernicus Climate Data Store (CDS)**:  
   [https://cds.climate.copernicus.eu/user/register](https://cds.climate.copernicus.eu/user/register)
2. Register for an account and verify your email.
3. Once logged in, go to **My Account** â†’ **API key**.

### 2ï¸âƒ£ **Locate Your API Credentials**
Your CDS API key will look something like this:

```
url: https://cds.climate.copernicus.eu/api/v2
key: 12345678-abcd-1234-efgh-56789abcdefg
```

### 3ï¸âƒ£ **Set Up `.cdsapirc` File**
You need to store your API credentials in a hidden file `.cdsapirc` in your **home directory**.

#### ğŸ“ **On Linux/Mac:**
1. Open a terminal and run:
   ```sh
   nano ~/.cdsapirc
   ```
2. Paste the following content, replacing `your-key`:
   ```
   url: https://cds.climate.copernicus.eu/api/v2
   key: 12345678-abcd-1234-efgh-56789abcdefg
   verify: 0
   ```
3. Save and exit (`CTRL + X`, then `Y`, then `ENTER`).

#### ğŸ“ **On Windows:**
1. Open **Notepad** and paste the API key in the same format as above.
2. Save it as `.cdsapirc` in `C:\Users\YourUsername\`.
3. Make sure the file type is **All Files (`*.*`)** and not `.txt`.

### 4ï¸âƒ£ **Verify Installation**
After setting up the credentials, verify they are working by running:
```sh
python -c "import cdsapi; c = cdsapi.Client(); print('CDS API setup successful!')"
```

If there are no errors, your CDS API is correctly configured! âœ…

## ğŸ”§ Setup Instructions

1. **Clone the repository:**

   ```bash
   git clone https://github.com/your-repo/forest-fire-tool.git
   cd forest-fire-tool
   ```

2. **Install dependencies:**

   ```bash
   pip install -r requirements.txt
   ```

3. **Create the API credentials folder manually:**
   The **`Data/credentials`** folder is excluded from version control. Create it manually and add the required JSON files:

   ```
   â”œâ”€â”€ ğŸ“ Data
   â”‚   â”œâ”€â”€ ğŸ“ credentials
   â”‚       â”œâ”€â”€ credentials.json      # Contains API username & password
   â”‚       â”œâ”€â”€ access_token.json     # Stores generated access tokens
   ```

4. **Populate `credentials.json`** with the following format:
   ```json
   {
     "username": "your_username",
     "password": "your_password"
   }
   ```

---

## ğŸš€ Running the Tool

### 1ï¸âƒ£ **Run the Main Script**

```bash
python main.py
```

It will prompt you for:

- **Province** (e.g., `"Alberta"`)
- **Start Date** (`YYYY-MM-DD`)
- **End Date** (`YYYY-MM-DD`)

This script will:
âœ… Download & process **climate**, **NDVI**, **fire history**, and **topographical** data  
âœ… Merge everything into **one structured CSV file**  
âœ… Save results under `Output/Requests/Request_YYYYMMDD_HHMM/`

---

## ğŸ“Š Understanding the Data Outputs

Each request generates a **timestamped folder** inside `Output/Requests/`.  
Inside this folder, you'll find:

### ğŸ”¹ **Climate Data (`aggregated_climate_data.csv`)**

| GridID | Date       | Wind Speed U | Wind Speed V | Temperature | Surface Pressure | Precipitation | Latitude | Longitude |
| ------ | ---------- | ------------ | ------------ | ----------- | ---------------- | ------------- | -------- | --------- |
| 1      | 2023-05-01 | -0.37        | -0.27        | 276.23      | 80018.0          | 1.28e-06      | 53.34    | -119.68   |

---

### ğŸ”¹ **Fire History (`fire_history_processed.csv`)**

| grid_id | Date       | Total Fire Size | Fire Occurred | Fire Cause | Latitude | Longitude |
| ------- | ---------- | --------------- | ------------- | ---------- | -------- | --------- |
| 436     | 2023-05-01 | 6422.17         | 1             | Natural    | 56.30    | -119.98   |

ğŸš¨ **If no fire data is found for a grid,**

- `Fire_Occurred = 0`
- `Total_Fire_Size = 0`
- `Fire_Cause = NaN`

---

### ğŸ”¹ **NDVI Data (`interpolated_ndvi.csv`)**

| grid_id | date       | ndvi |
| ------- | ---------- | ---- |
| 1       | 2023-05-01 | 0.34 |
| 2       | 2023-05-01 | 0.29 |

ğŸš¨ **If no NDVI is found, NDVI = NaN**

---

### ğŸ”¹ **Topographical Data (`processed_topo.csv`)**

| grid_id | Latitude | Longitude | Elevation | Slope | Aspect |
| ------- | -------- | --------- | --------- | ----- | ------ |
| 1       | 53.34    | -119.68   | 962.05    | 35.0  | 161.71 |

ğŸš¨ **If no data found, values will be NaN**

---

### ğŸ”¹ **Final Merged Dataset (`merged_data.csv`)**

| grid_id | Latitude | Longitude | Date       | Climate Variables | Fire History | NDVI | Topography |
| ------- | -------- | --------- | ---------- | ----------------- | ------------ | ---- | ---------- |
| 1       | 53.34    | -119.68   | 2023-05-01 | âœ…                | âœ…           | âœ…   | âœ…         |
| 2       | 53.43    | -119.74   | 2023-05-01 | âœ…                | âŒ           | âœ…   | âœ…         |

ğŸš¨ **Missing values are handled as `NaN` for ML compatibility.**

---

## ğŸ›  Troubleshooting

### âŒ **Issue: "No API token found"**

âœ… **Fix**: Run the following command to create & store an access token:

```bash
python generate_token.py
```

### âŒ **Issue: "Data missing in final CSV"**

- Ensure all individual scripts **ran successfully** inside `Output/Requests/Request_YYYYMMDD_HHMM/`
- If any data is missing, check logs and rerun that specific script.

---

## ğŸ”® Future Enhancements

âœ” Add more **weather variables** like humidity & solar radiation  
âœ” Support **larger regions** by dividing grids dynamically  
âœ” Improve **data interpolation** for NDVI

---

## â¤ï¸ Contributing

Feel free to submit **pull requests** or report **issues**!

---

ğŸš€ **Developed by:** Dheemanth 
ğŸ“… **Last Updated:** `2025-02-03`

---

This README should provide everything needed for new users to **set up, run, and understand** the tool. Let me know if you'd like any refinements! ğŸš€ğŸ”¥
